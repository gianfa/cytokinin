{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a complete example of fitting is shown.  \n",
    "This is intended only for explainatory purpose, then fine tuning or correctness are not the aims of this notebook. You can alway make it better submitting a PR ðŸ˜‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workspace setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "log = logging.getLogger()\n",
    "log.setLevel(logging.INFO)\n",
    "pil_logger = logging.getLogger('PIL')\n",
    "pil_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('./../') # quite the same as str\n",
    "\n",
    "# Set an example dir for images files\n",
    "MOCKS = root.joinpath('./../cytokinin/cytokinin/tests/mocks/')\n",
    "IMGS = MOCKS/'imgs' # this is another Path object\n",
    "os.listdir(str(IMGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cytokinin as ck\n",
    "from cytokinin.data import take_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data from two roots: dogs and stones\n",
    "dogs = take_data('images').store_filesnames_from_folder(IMGS.joinpath('dog'))\n",
    "stones = take_data('images').store_filesnames_from_folder(IMGS.joinpath('stone'))\n",
    "dands = dogs.copy().add_from_data(stones)\n",
    "\n",
    "csv_url = MOCKS/'labels'/'dogsandstones_labes.csv'\n",
    "dands.label_from_csv(csv_url, col='Y')\n",
    "print(dands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just define a Pytorch [tranforms object](https://pytorch.org/docs/stable/torchvision/transforms.html) for the Data object and you'll be ready to pass it to a Pytorch [Dataloader](https://pytorch.org/docs/stable/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.Resize((224,224),interpolation=2), # NEEDED if you want to use *batch_size*\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dands.set_transforms(transformations)\n",
    "print(dands.torch_tsfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8\n",
    "train_loader = DataLoader(dands, batch_size=bs, shuffle=True)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import LongTensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "log.setLevel(logging.INFO)\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "model.fc = nn.Linear(512 * models.resnet.BasicBlock.expansion, 2)\n",
    "net = model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "nepochs = 2\n",
    "for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        prp = i*100/len(train_loader)\n",
    "        print(f'{prp}% of epoch {epoch}/{nepochs}')\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        labels = labels.type(LongTensor)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
